This assignment includes the notebook file that implements a simple version of GloVe, which embeds words into a k-dimensional vector, and then trains a neural net (based off of the Masked Language Modeling objective introduced in BERT) to predict missing key words in the sentence.

Reference to the GloVe paper: 

Richard Socher Jeffrey Pennington and Christopher D Manning. Glove: Global vectors for word representation. Citeseer.

Reference to the neural net that trains via masked language modeling: 

Yoshua Bengio, R ́ejean Ducharme, Pascal Vincent, and Christian Jauvin. A neural probabilistic language model. Journal of machine learning research, 3(Feb):1137–1155, 2003.

